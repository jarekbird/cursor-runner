# TASK-PY-004: Implement Structured Logging

**Section**: 2. Project Setup
**Subsection**: 2.3
**Task ID**: TASK-PY-004

## Description

This task implements a structured logging system for `cursor-executor` that provides consistent, production-ready logging with contextual information. The logger must support JSON or key-value output formats suitable for log aggregation systems, respect log levels from configuration, and provide helper functions to attach context (requestId, conversationId, queueType, repository) to log entries.

The logging system is critical for debugging, monitoring, and operational visibility. It must:
- Support structured output (JSON or key-value pairs)
- Include standard fields: level, timestamp, message, service, requestId, queueType, repository
- Respect `LOG_LEVEL` environment variable from system settings
- Provide context-aware logging helpers
- Replace any `print` statements with proper logging

This module will be used by all services throughout the application, so it must be well-designed, performant, and easy to use.

**Reference Implementation**: `VirtualAssistant/cursor-runner/src/logger.ts`

## Current State

- TASK-PY-003 has been completed, providing system settings including `log_level`
- Basic logging may exist in the health endpoint (from TASK-PY-002) but is not structured
- No centralized logging configuration exists
- No context-aware logging helpers exist
- Any `print` statements need to be replaced with proper logging

**Important**: This task should be executed after TASK-PY-003 (configuration) so logging can use settings, and before service implementations that need logging.

## Checklist

### Preparation and Setup

- [ ] Review Node.js `logger.ts` to understand logging structure and fields
- [ ] Review how Node.js logger is used throughout the codebase
- [ ] Decide on logging format: JSON (for production) vs key-value (for readability)
- [ ] Review Python logging best practices and structured logging libraries
- [ ] Identify all places where `print` statements exist (if any)

### Implementation Steps

- [ ] Step 1: Create logger module structure
  - [ ] Create `cursor_executor/services/logger.py`
  - [ ] Import required dependencies: `logging`, `json`, `sys`, `datetime`
  - [ ] Import system settings to access `log_level`
  - [ ] Consider using `python-json-logger` or similar for JSON formatting
- [ ] Step 2: Configure root logger
  - [ ] Set up logging configuration based on `log_level` from settings
  - [ ] Create custom formatter for structured output
  - [ ] Configure handler (console for development, can add file handler later)
  - [ ] Set appropriate log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- [ ] Step 3: Implement structured formatter
  - [ ] Create `StructuredFormatter` class extending `logging.Formatter`
  - [ ] Format log records as JSON or key-value pairs
  - [ ] Include standard fields:
    - [ ] `level`: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    - [ ] `timestamp`: ISO 8601 formatted timestamp
    - [ ] `message`: Log message
    - [ ] `service`: Service name ("cursor-executor")
    - [ ] `requestId`: Optional request ID (from context)
    - [ ] `conversationId`: Optional conversation ID (from context)
    - [ ] `queueType`: Optional queue type (default, telegram, api)
    - [ ] `repository`: Optional repository name (from context)
    - [ ] `module`: Python module name
    - [ ] `function`: Function name
    - [ ] `line`: Line number
- [ ] Step 4: Create context-aware logger
  - [ ] Create `get_logger(name: str)` function that returns a logger instance
  - [ ] Create `LoggerContext` class or dict to hold contextual information
  - [ ] Implement context manager or thread-local storage for request context
  - [ ] Provide helper functions:
    - [ ] `set_request_context(request_id: str, queue_type: str = None, repository: str = None)`
    - [ ] `clear_request_context()`
    - [ ] `get_logger_with_context(name: str, **context)`
- [ ] Step 5: Implement convenience logging functions
  - [ ] `log_info(message: str, **kwargs)` - Log at INFO level with context
  - [ ] `log_warning(message: str, **kwargs)` - Log at WARNING level with context
  - [ ] `log_error(message: str, **kwargs)` - Log at ERROR level with context
  - [ ] `log_debug(message: str, **kwargs)` - Log at DEBUG level with context
  - [ ] All functions should automatically include context if available
- [ ] Step 6: Integrate with FastAPI
  - [ ] Create FastAPI middleware for request logging
  - [ ] Extract request ID from headers or generate one
  - [ ] Extract IP address and user-agent
  - [ ] Set request context at start of request
  - [ ] Clear context at end of request
  - [ ] Log request/response information
- [ ] Step 7: Replace print statements
  - [ ] Search codebase for `print()` statements
  - [ ] Replace with appropriate logging calls
  - [ ] Ensure all logging uses the structured logger

### Specific Requirements

- [ ] Requirement 1: Structured output format
  - Acceptance criteria: Logs are formatted as JSON or key-value pairs
  - Acceptance criteria: All standard fields are included in every log entry
  - Acceptance criteria: Context fields are included when available
- [ ] Requirement 2: Log level configuration
  - Acceptance criteria: `LOG_LEVEL` environment variable controls logging verbosity
  - Acceptance criteria: Log level can be set to DEBUG, INFO, WARNING, ERROR, CRITICAL
  - Acceptance criteria: Default log level is INFO
- [ ] Requirement 3: Context-aware logging
  - Acceptance criteria: Request ID can be attached to all logs in a request
  - Acceptance criteria: Conversation ID can be attached to logs
  - Acceptance criteria: Queue type and repository can be attached to logs
  - Acceptance criteria: Context persists across function calls within a request
- [ ] Requirement 4: Performance
  - Acceptance criteria: Logging does not significantly impact request performance
  - Acceptance criteria: Debug logs can be disabled in production
  - Acceptance criteria: Log formatting is efficient

### Error Handling and Edge Cases

- [ ] Handle case where log level is invalid: Default to INFO with warning
- [ ] Handle case where context is not set: Logs should still work without context fields
- [ ] Handle case where JSON serialization fails: Fall back to string representation
- [ ] Handle case where logging configuration fails: Use basic logging as fallback
- [ ] Handle case where context is accessed from different threads: Use thread-local storage

### Testing

- [ ] Write `tests/test_logger.py`:
  - [ ] Test log level can be set via environment variable
  - [ ] Test structured output includes all required fields
  - [ ] Test context fields are included when set
  - [ ] Test context fields are not included when not set
  - [ ] Test log level filtering works (DEBUG logs don't appear at INFO level)
  - [ ] Test request context is set and cleared correctly
  - [ ] Test logger can be used from multiple modules
  - [ ] Test JSON serialization of log records
  - [ ] Test error handling when serialization fails
- [ ] Run `pytest tests/test_logger.py -v`
- [ ] Verify test coverage is >85% for logger.py
- [ ] **DO NOT manually test by running the server** - use automated tests instead
- [ ] Verify logs can be captured and parsed in tests

### Documentation

- [ ] Add docstrings to all logger functions and classes
- [ ] Document how to use the logger in code:
  - [ ] Basic usage: `logger = get_logger(__name__)`
  - [ ] With context: `set_request_context(request_id="...")`
  - [ ] Convenience functions: `log_info("message", repository="repo")`
- [ ] Document log format and fields in README
- [ ] Document how to configure log level
- [ ] Document how to add custom fields to logs

### Verification

- [ ] Verify structured output format is correct
- [ ] Verify log level configuration works
- [ ] Verify context is properly attached to logs
- [ ] Verify all print statements have been replaced
- [ ] Verify tests pass with >85% coverage
- [ ] Verify logs are readable and parseable

## Notes

- This task is part of Phase 2: Project Setup
- **Execution Timing**: Execute after TASK-PY-003 (configuration), before service implementations
- **Dependencies**: 
  - TASK-PY-003: Implement Configuration & Settings Module (must be complete for log_level)
- **Important Considerations**: 
  - Consider using `python-json-logger` library for JSON formatting
  - Thread-local storage may be needed for request context in async environments
  - FastAPI has built-in logging middleware that can be extended
  - Consider log rotation and file size limits for production
  - Sensitive data (secrets, tokens) should never be logged
- **Task Independence**: This task can be completed independently after configuration exists
- **Current State**: No structured logging exists yet

## Related Tasks

- Previous: TASK-PY-003 (Implement Configuration & Settings Module)
- Next: TASK-PY-005 (Implement SQLite Migration Framework)
- Dependencies:
  - TASK-PY-003: System settings needed for log_level
- Related:
  - TASK-PY-002: Health endpoint may have basic logging to replace
  - TASK-PY-014: HTTP API will use logging for all requests
  - All future service tasks will use this logger

## Definition of Done

This task involves **CODE/FILE WRITING** - creating Python source code files.

**Description**: Tasks that involve writing, creating, modifying, or implementing SOURCE CODE FILES that need to be committed to git.

**Definition of Done**: "A Pull Request was created OR code was pushed to origin with the task complete"

**User Stories**:
- As a **developer**, I need structured logging so I can debug issues with contextual information
- As an **operator**, I need log aggregation so I can monitor the system in production
- As a **developer**, I need context-aware logging so I can trace requests across services
- As a **developer**, I need configurable log levels so I can control verbosity

**Automated Tests**:
- `tests/test_logger.py`:
  - Test log level can be set via environment variable
  - Test structured output includes all required fields (level, timestamp, message, service)
  - Test context fields (requestId, conversationId, queueType, repository) are included when set
  - Test context fields are omitted when not set
  - Test log level filtering works correctly
  - Test request context is set and cleared
  - Test logger works from multiple modules
  - Test JSON serialization works
  - Test error handling for invalid inputs
- All tests must pass: `pytest tests/test_logger.py -v`
- Test coverage should be >85%: `pytest --cov=cursor_executor/services/logger --cov-report=term-missing`

**Commit and Push Requirements**:
- [ ] Stage all new files: `git add cursor_executor/services/logger.py`
- [ ] Stage updated files: `git add cursor_executor/api/server.py` (if logging middleware added)
- [ ] Commit with descriptive message: `git commit -m "TASK-PY-004: Implement structured logging

- Add structured logger with JSON/key-value output
- Support context fields (requestId, conversationId, queueType, repository)
- Add FastAPI middleware for request logging
- Replace print statements with proper logging
- Add comprehensive tests with >85% coverage"`
- [ ] Push to origin: `git push origin <branch-name>`
- [ ] Verify commit appears in remote repository
- [ ] Verify CI/CD (if configured) runs tests successfully

**Completion Criteria**:
- [ ] `logger.py` module exists with structured logging
- [ ] Log level is configurable via environment variable
- [ ] Context-aware logging helpers exist
- [ ] FastAPI middleware logs requests
- [ ] All print statements replaced with logging
- [ ] Tests pass with >85% coverage
- [ ] Documentation is complete
- [ ] All code is committed and pushed to origin
